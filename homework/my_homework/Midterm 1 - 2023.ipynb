{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b2f936",
   "metadata": {},
   "source": [
    "# Midterm 1\n",
    "\n",
    "## FINM 36700 - 2023\n",
    "\n",
    "### UChicago Financial Mathematics\n",
    "\n",
    "* Mark Hendricks\n",
    "* hendricks@uchicago.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af28e7fd",
   "metadata": {},
   "source": [
    "# Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd63ff",
   "metadata": {},
   "source": [
    "## Please note the following:\n",
    "\n",
    "Points\n",
    "* The exam is 100 points.\n",
    "* You have 120 minutes to complete the exam.\n",
    "* For every minute late you submit the exam, you will lose one point.\n",
    "Final Exam\n",
    "\n",
    "Submission\n",
    "* You will upload your solution to the `Midterm 1` assignment on Canvas, where you downloaded this. (Be sure to **submit** on Canvas, not just **save** on Canvas.\n",
    "* Your submission should be readable, (the graders can understand your answers,) and it should **include all code used in your analysis in a file format that the code can be executed.** \n",
    "\n",
    "Rules\n",
    "* The exam is open-material, closed-communication.\n",
    "* You do not need to cite material from the course github repo--you are welcome to use the code posted there without citation.\n",
    "\n",
    "Advice\n",
    "* If you find any question to be unclear, state your interpretation and proceed. We will only answer questions of interpretation if there is a typo, error, etc.\n",
    "* The exam will be graded for partial credit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1960a3c5",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "**All data files are found in the class github repo, in the `data` folder.**\n",
    "\n",
    "This exam makes use of the following data files:\n",
    "* `midterm_data_1.xlsx`\n",
    "\n",
    "This file has sheets for...\n",
    "* `info` - names of each stock ticker\n",
    "* `excess returns` - weekly excess returns on several stocks\n",
    "* `SPY` - weekly excess returns on SPY\n",
    "\n",
    "Note the data is **weekly** so any annualizations should use `52` weeks in a year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f6568",
   "metadata": {},
   "source": [
    "#### If useful\n",
    "here is code to load in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "344abdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "FILEIN = '../data/midterm_1_data.xlsx'\n",
    "sheet_exrets = 'excess returns'\n",
    "sheet_spy = 'spy'\n",
    "\n",
    "retsx = pd.read_excel(FILEIN, sheet_name=sheet_exrets).set_index('date')\n",
    "spy = pd.read_excel(FILEIN, sheet_name=sheet_spy).set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0af33e1",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "| Problem | Points |\n",
    "|---------|--------|\n",
    "| 1       | 20     |\n",
    "| 2       | 35     |\n",
    "| 3       | 30     |\n",
    "| 4       | 15     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c158c236",
   "metadata": {},
   "source": [
    "### Each numbered question is worth 5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362090a7",
   "metadata": {},
   "source": [
    "### Notation\n",
    "(Hidden LaTeX commands)\n",
    "\n",
    "$$\\newcommand{\\mux}{\\tilde{\\boldsymbol{\\mu}}}$$\n",
    "$$\\newcommand{\\wtan}{\\boldsymbol{\\text{w}}^{\\text{tan}}}$$\n",
    "$$\\newcommand{\\wtarg}{\\boldsymbol{\\text{w}}^{\\text{port}}}$$\n",
    "$$\\newcommand{\\mutarg}{\\tilde{\\boldsymbol{\\mu}}^{\\text{port}}}$$\n",
    "$$\\newcommand{\\wEW}{\\boldsymbol{\\text{w}}^{\\text{EW}}}$$\n",
    "$$\\newcommand{\\wRP}{\\boldsymbol{\\text{w}}^{\\text{RP}}}$$\n",
    "$$\\newcommand{\\wREG}{\\boldsymbol{\\text{w}}^{\\text{REG}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40926a81",
   "metadata": {},
   "source": [
    "# 1. Short Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29c0d60",
   "metadata": {},
   "source": [
    "### No Data Needed\n",
    "\n",
    "These problem does not require any data file. Rather, analyze the situation conceptually, based on the information below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d086f971",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "In what sense was ProShares `HDG` successful in hedging the `HFRI`, and in what sense was it unsuccessful in tracking the `HFRI`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d80470",
   "metadata": {},
   "source": [
    "<font color='orange'>\n",
    "Answer: ProShares replied HFRI in terms of variarion (because of that they showed a high correlation and R-squared), but they got a lower return in comparison with HFRI, having a lower Sharpe Ratio.\n",
    "<font color='orange'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ddf91",
   "metadata": {},
   "source": [
    "## 2\n",
    "\n",
    "We discussed multiple ways of calculating Value-at-Risk (VaR). What are the tradeoffs between using the normal distribution formula versus a directly empirical approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cc007e",
   "metadata": {},
   "source": [
    "<font color='orange'>\n",
    "Answer: \n",
    "\n",
    "* By using a normal distribution, we are assuming that the returns distributited normaly and which does not take into account the real tails of the returns (skwenss and Kurtorsis of the sample) . But you can prodive a good estimation with less data available\n",
    "\n",
    "* On the other hand, the empirical or historial VaR, relaid on the data available, that means it's going to interpolate the percentile if the sample does not have enough data. It also assume iid returns. But it does not require any assumption on the data distribution and it is easy to implement\n",
    "\n",
    "\n",
    "<font color='orange'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b7e68",
   "metadata": {},
   "source": [
    "## 3\n",
    "\n",
    "Did we find that **TIPS** have been useful in expanding the mean-variance frontier in the past? Did we conclude they might be useful in the future? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e84667",
   "metadata": {},
   "source": [
    "<font color='orange'>\n",
    "Answer: The tangent portfolio didn't change by excluding TIPS, but it could be usuful in the future, since in the HW 2 by only changing the expected return on one standard desviation the fronteir was expanded  \n",
    "<font color='orange'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea97348b",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "What aspect of the classic mean-variance optimization approach leads to extreme answers? How did regularization help with this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6916c",
   "metadata": {},
   "source": [
    "<font color='orange'>\n",
    "Answer: When the covariance matrix is nearly singular (ie. det( $\\_sigma$ ) ~ 0), the result of the Mean-Variance optimization show a high variability of the weightes to a change on the expeted returns. Therefore it applifies the possible errors of the mean return stimations. By regularazing the covariance matrix, the covariance (not the variances of the assets) is reduced to the half, decreasing the estimated dependence of the assets and therefore reducioning the changes respect to the variation of the expected returns\n",
    "<font color='orange'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e42346",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d66389e",
   "metadata": {},
   "source": [
    "# 2. Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b67603",
   "metadata": {},
   "source": [
    "Consider a mean-variance optimization of **excess** returns provided in `midterm_1_data.xlsx.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0ebf220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew,kurtosis,norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c690ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(port_metrics,weights = [],adj_factor = 12):\n",
    "    if len(weights) == 0:\n",
    "        port_metrics_r = pd.DataFrame({\"Mean\": port_metrics.mean()*adj_factor,\"Volatility\":port_metrics.std()*np.sqrt(adj_factor)})\n",
    "        port_metrics_r[\"Sharpe_Ratio\"] = (port_metrics.mean() / port_metrics.std()) * np.sqrt(adj_factor)\n",
    "        port_metrics_r[\"Skew\"] = skew(port_metrics)\n",
    "        port_metrics_r[\"Excess Kurtosis\"] = kurtosis(port_metrics, fisher=True)    \n",
    "    else:\n",
    "        port_metrics = port_metrics @ weights\n",
    "        port_metrics_r = pd.DataFrame({\"Mean\": port_metrics.mean()*adj_factor,\"Volatility\":port_metrics.std()*np.sqrt(adj_factor)})\n",
    "        port_metrics_r[\"Sharpe_Ratio\"] = (port_metrics.mean() / port_metrics.std()) * np.sqrt(adj_factor)\n",
    "        port_metrics_r[\"Skew\"] = skew(port_metrics)\n",
    "        port_metrics_r[\"Excess Kurtosis\"] = kurtosis(port_metrics, fisher=True)\n",
    "    return port_metrics_r\n",
    "\n",
    "def VaR_CVaR_Drawdown_metrics(data_daily_return):\n",
    "    result = pd.DataFrame()\n",
    "    for asset in data_daily_return.columns:\n",
    "\n",
    "        data_aux = data_daily_return[[asset]].copy()\n",
    "\n",
    "            \n",
    "        VaR = np.percentile(sorted(data_aux.values),q = 5)\n",
    "        CVaR = data_aux[data_aux[asset] <= VaR].mean().values[0]\n",
    "\n",
    "        data_aux_acum_return = (data_aux + 1).cumprod()\n",
    "        data_aux_max_cum_return = data_aux_acum_return.cummax()\n",
    "        data_aux_drawdown = ((data_aux_acum_return-data_aux_max_cum_return)/data_aux_max_cum_return)\n",
    "        max_drawdown = data_aux_drawdown.min().values[0]\n",
    "        max_drawdown_date = data_aux_drawdown.idxmin().values[0]\n",
    "        peak_idx = data_aux_max_cum_return.idxmax().values[0]\n",
    "\n",
    "        recovery_idx = data_aux_drawdown[data_aux_drawdown.idxmin().values[0]:].gt(-0.00001).idxmax().values[0]\n",
    "\n",
    "        aux_result = pd.DataFrame([[VaR,CVaR,max_drawdown,max_drawdown_date,peak_idx,recovery_idx,(recovery_idx - max_drawdown_date)/ np.timedelta64(1, 'D')]], columns= [\"VaR\",\"CVaR\",\"Max Drawdown\",\"Bottom\",\"Peak\",\"Recovery\",\"Duration (days)\"], index = [asset])\n",
    "        result = pd.concat([result,aux_result],axis=0)\n",
    "\n",
    "    return result,data_aux_drawdown\n",
    "\n",
    "def get_metrics_all(returns,adj_factor = 12):\n",
    "    metrics1 = get_metrics(returns,adj_factor = 12)\n",
    "    metrics2,_ = VaR_CVaR_Drawdown_metrics(returns)\n",
    "    return pd.merge(metrics1,metrics2, left_index= True, right_index=True, how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6a6ba",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "Report the following **annualized** statistics:\n",
    "* mean\n",
    "* volatility\n",
    "* Sharpe ratio\n",
    "\n",
    "Which assets have the highest / lowest Sharpe ratios?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5903e8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ac29b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ac29b_level0_col0\" class=\"col_heading level0 col0\" >Mean</th>\n",
       "      <th id=\"T_ac29b_level0_col1\" class=\"col_heading level0 col1\" >Volatility</th>\n",
       "      <th id=\"T_ac29b_level0_col2\" class=\"col_heading level0 col2\" >Sharpe_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ac29b_level0_row0\" class=\"row_heading level0 row0\" >NVDA</th>\n",
       "      <td id=\"T_ac29b_row0_col0\" class=\"data row0 col0\" >65.07%</td>\n",
       "      <td id=\"T_ac29b_row0_col1\" class=\"data row0 col1\" >46.81%</td>\n",
       "      <td id=\"T_ac29b_row0_col2\" class=\"data row0 col2\" >139.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ac29b_level0_row1\" class=\"row_heading level0 row1\" >MSFT</th>\n",
       "      <td id=\"T_ac29b_row1_col0\" class=\"data row1 col0\" >28.81%</td>\n",
       "      <td id=\"T_ac29b_row1_col1\" class=\"data row1 col1\" >24.02%</td>\n",
       "      <td id=\"T_ac29b_row1_col2\" class=\"data row1 col2\" >119.93%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ac29b_level0_row2\" class=\"row_heading level0 row2\" >AAPL</th>\n",
       "      <td id=\"T_ac29b_row2_col0\" class=\"data row2 col0\" >31.94%</td>\n",
       "      <td id=\"T_ac29b_row2_col1\" class=\"data row2 col1\" >28.39%</td>\n",
       "      <td id=\"T_ac29b_row2_col2\" class=\"data row2 col2\" >112.52%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ac29b_level0_row3\" class=\"row_heading level0 row3\" >TSLA</th>\n",
       "      <td id=\"T_ac29b_row3_col0\" class=\"data row3 col0\" >56.97%</td>\n",
       "      <td id=\"T_ac29b_row3_col1\" class=\"data row3 col1\" >60.70%</td>\n",
       "      <td id=\"T_ac29b_row3_col2\" class=\"data row3 col2\" >93.86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ac29b_level0_row4\" class=\"row_heading level0 row4\" >AMZN</th>\n",
       "      <td id=\"T_ac29b_row4_col0\" class=\"data row4 col0\" >23.95%</td>\n",
       "      <td id=\"T_ac29b_row4_col1\" class=\"data row4 col1\" >31.04%</td>\n",
       "      <td id=\"T_ac29b_row4_col2\" class=\"data row4 col2\" >77.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ac29b_level0_row5\" class=\"row_heading level0 row5\" >GOOGL</th>\n",
       "      <td id=\"T_ac29b_row5_col0\" class=\"data row5 col0\" >19.33%</td>\n",
       "      <td id=\"T_ac29b_row5_col1\" class=\"data row5 col1\" >27.42%</td>\n",
       "      <td id=\"T_ac29b_row5_col2\" class=\"data row5 col2\" >70.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ac29b_level0_row6\" class=\"row_heading level0 row6\" >XOM</th>\n",
       "      <td id=\"T_ac29b_row6_col0\" class=\"data row6 col0\" >12.42%</td>\n",
       "      <td id=\"T_ac29b_row6_col1\" class=\"data row6 col1\" >31.16%</td>\n",
       "      <td id=\"T_ac29b_row6_col2\" class=\"data row6 col2\" >39.86%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2a8a3d13050>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_ex_return = get_metrics(retsx, adj_factor=52)[[\"Mean\",\"Volatility\",\"Sharpe_Ratio\"]]\n",
    "metrics_ex_return = metrics_ex_return.sort_values(by = [\"Sharpe_Ratio\"],ascending=False)\n",
    "metrics_ex_return.style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ead8dfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The asset with the highest Sharpe Ratio is \n",
      "       Sharpe_Ratio\n",
      "NVDA      1.390011 \n",
      " and the asset with the lowest SR is: \n",
      "      Sharpe_Ratio\n",
      "XOM      0.398557\n"
     ]
    }
   ],
   "source": [
    "print(f\"The asset with the highest Sharpe Ratio is \\n {metrics_ex_return[[\"Sharpe_Ratio\"]].head(1)} \\n and the asset with the lowest SR is: \\n {metrics_ex_return[[\"Sharpe_Ratio\"]].tail(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f091c84",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "Report the weights of the tangency portfolio.\n",
    "\n",
    "Also report the Sharpe ratio achieved by the tangency portfolio over this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a017102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_tang(return_db, adj_factor = 12):\n",
    "    sigma = (return_db.cov()*adj_factor)\n",
    "    mu_excess = (return_db.mean()*adj_factor)\n",
    "    vector = np.ones(len(mu_excess))\n",
    "    w_tan = (np.linalg.inv(sigma) @ mu_excess )/(np.transpose(vector) @ np.linalg.inv(sigma) @ mu_excess)\n",
    "    weights_db = pd.DataFrame({\"w_tan\": w_tan})\n",
    "    weights_db.index = return_db.columns\n",
    "    return weights_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8dba558",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tanget = weights_tang(retsx, adj_factor = 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "542ce5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Sharpe_Ratio</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Excess Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w_tan</th>\n",
       "      <td>0.563474</td>\n",
       "      <td>0.358351</td>\n",
       "      <td>1.572409</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>1.859662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean  Volatility  Sharpe_Ratio      Skew  Excess Kurtosis\n",
       "w_tan  0.563474    0.358351      1.572409  0.004363         1.859662"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(retsx @ w_tanget, adj_factor = 52)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1bab65",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "* What weight is given to the asset with the lowest Sharpe ratio?\n",
    "* What Sharpe ratio does the lowest (most negative) weight asset have?\n",
    "\n",
    "Explain. Support your answer with evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bed147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tanget_port = pd.merge(metrics_ex_return,w_tanget, left_index=True, right_index=True, how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "135d1a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The asset with the hightest SR 1.3900105643328675 has a weight of NVDA    0.495996\n",
      "Name: w_tan, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Sharpe_Ratio</th>\n",
       "      <th>w_tan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>0.650658</td>\n",
       "      <td>0.468096</td>\n",
       "      <td>1.390011</td>\n",
       "      <td>0.495996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean  Volatility  Sharpe_Ratio     w_tan\n",
       "NVDA  0.650658    0.468096      1.390011  0.495996"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The asset with the lowest weight GOOGL   -0.502721\n",
      "Name: w_tan, dtype: float64 has a SR of GOOGL    0.70502\n",
      "Name: Sharpe_Ratio, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Sharpe_Ratio</th>\n",
       "      <th>w_tan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.193328</td>\n",
       "      <td>0.274217</td>\n",
       "      <td>0.70502</td>\n",
       "      <td>-0.502721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean  Volatility  Sharpe_Ratio     w_tan\n",
       "GOOGL  0.193328    0.274217       0.70502 -0.502721"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"The asset with the hightest SR {Tanget_port[\"Sharpe_Ratio\"].max()} has a weight of {Tanget_port.loc[(Tanget_port[\"Sharpe_Ratio\"] == Tanget_port[\"Sharpe_Ratio\"].max()),\"w_tan\"]}\")\n",
    "display(Tanget_port[(Tanget_port[\"Sharpe_Ratio\"] == Tanget_port[\"Sharpe_Ratio\"].max())])\n",
    "\n",
    "print(f\"The asset with the lowest weight {Tanget_port.loc[(Tanget_port[\"w_tan\"] == Tanget_port[\"w_tan\"].min()),\"w_tan\"]} has a SR of {Tanget_port.loc[(Tanget_port[\"w_tan\"] == Tanget_port[\"w_tan\"].min()),\"Sharpe_Ratio\"]}\")\n",
    "display(Tanget_port.loc[(Tanget_port[\"w_tan\"] == Tanget_port[\"w_tan\"].min()),:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131963d5",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "Let's examine the out-of-sample performance.\n",
    "\n",
    "Calculate and report the following three allocations using only data through the end of 2022:\n",
    "* tangency portfolio\n",
    "* equally weighted portfolio\n",
    "* a regularized approach, with a new formula shown below\n",
    "\n",
    "where\n",
    "$$\\wEW_i = \\frac{1}{n}$$\n",
    "\n",
    "$$\\wREG \\sim \\widehat{\\Sigma}^{-1}\\mux$$\n",
    "\n",
    "$$\\widehat{\\Sigma} = \\frac{\\Sigma + \\boldsymbol{2}\\,\\Sigma_D}{\\boldsymbol{3}}$$\n",
    "where $\\Sigma_D$ denotes a *diagonal* matrix of the security variances, with zeros in the off-diagonals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c09106d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_tang(return_db, adj_factor = 12):\n",
    "    sigma = (return_db.cov()*adj_factor)\n",
    "    mu_excess = (return_db.mean()*adj_factor)\n",
    "    vector = np.ones(len(mu_excess))\n",
    "    w_tan = (np.linalg.inv(sigma) @ mu_excess )/(np.transpose(vector) @ np.linalg.inv(sigma) @ mu_excess)\n",
    "    weights_db = pd.DataFrame({\"w_tan\": w_tan})\n",
    "    weights_db.index = return_db.columns\n",
    "    return weights_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e05472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_tag_reg(return_db, adj_factor = 12, diagonal_factor = 2, denominator = 3):\n",
    "    sigma = (return_db.cov()*adj_factor)\n",
    "    sigma_reg = (sigma + diagonal_factor*np.diag(np.diag(sigma)))/denominator\n",
    "    mu_excess = (return_db.mean()*adj_factor)\n",
    "    vector = np.ones(len(mu_excess))\n",
    "    w_tan = (np.linalg.inv(sigma_reg) @ mu_excess )/(np.transpose(vector) @ np.linalg.inv(sigma_reg) @ mu_excess)\n",
    "    weights_db = pd.DataFrame({\"w_tan_reg\": w_tan})\n",
    "    weights_db.index = return_db.columns\n",
    "    return weights_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ca9227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_equally_weighted(return_db):\n",
    "    n = len(return_db.columns)\n",
    "    weights_db = pd.DataFrame({\"w_equally_weighted\": [1/n]*n})\n",
    "    weights_db.index = return_db.columns\n",
    "    return weights_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1282696",
   "metadata": {},
   "outputs": [],
   "source": [
    "retsx_2022 = retsx[retsx.index <= \"2022-12-31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe7ed050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Sharpe_Ratio</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Excess Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w_tan</th>\n",
       "      <td>0.563474</td>\n",
       "      <td>0.358351</td>\n",
       "      <td>1.572409</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>1.859662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean  Volatility  Sharpe_Ratio      Skew  Excess Kurtosis\n",
       "w_tan  0.563474    0.358351      1.572409  0.004363         1.859662"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(retsx @ w_tanget, adj_factor = 52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d596d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tanget = weights_tang(retsx_2022, adj_factor = 52)\n",
    "w_equally_weighted = weights_equally_weighted(retsx_2022)\n",
    "q_tag_reg = weights_tag_reg(retsx_2022, adj_factor = 52, diagonal_factor = 2, denominator = 3)\n",
    "\n",
    "in_sample_w = pd.merge(pd.merge(w_tanget,w_equally_weighted, left_index=True, right_index=True, how = \"left\"),q_tag_reg, left_index=True, right_index=True, how = \"left\")\n",
    "in_sample_metrics = get_metrics(retsx_2022 @ in_sample_w, adj_factor = 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4d8ae39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_5b1fd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5b1fd_level0_col0\" class=\"col_heading level0 col0\" >w_tan</th>\n",
       "      <th id=\"T_5b1fd_level0_col1\" class=\"col_heading level0 col1\" >w_equally_weighted</th>\n",
       "      <th id=\"T_5b1fd_level0_col2\" class=\"col_heading level0 col2\" >w_tan_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5b1fd_level0_row0\" class=\"row_heading level0 row0\" >AAPL</th>\n",
       "      <td id=\"T_5b1fd_row0_col0\" class=\"data row0 col0\" >31.06%</td>\n",
       "      <td id=\"T_5b1fd_row0_col1\" class=\"data row0 col1\" >14.29%</td>\n",
       "      <td id=\"T_5b1fd_row0_col2\" class=\"data row0 col2\" >23.73%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b1fd_level0_row1\" class=\"row_heading level0 row1\" >MSFT</th>\n",
       "      <td id=\"T_5b1fd_row1_col0\" class=\"data row1 col0\" >107.31%</td>\n",
       "      <td id=\"T_5b1fd_row1_col1\" class=\"data row1 col1\" >14.29%</td>\n",
       "      <td id=\"T_5b1fd_row1_col2\" class=\"data row1 col2\" >33.08%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b1fd_level0_row2\" class=\"row_heading level0 row2\" >AMZN</th>\n",
       "      <td id=\"T_5b1fd_row2_col0\" class=\"data row2 col0\" >-25.91%</td>\n",
       "      <td id=\"T_5b1fd_row2_col1\" class=\"data row2 col1\" >14.29%</td>\n",
       "      <td id=\"T_5b1fd_row2_col2\" class=\"data row2 col2\" >4.72%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b1fd_level0_row3\" class=\"row_heading level0 row3\" >NVDA</th>\n",
       "      <td id=\"T_5b1fd_row3_col0\" class=\"data row3 col0\" >38.01%</td>\n",
       "      <td id=\"T_5b1fd_row3_col1\" class=\"data row3 col1\" >14.29%</td>\n",
       "      <td id=\"T_5b1fd_row3_col2\" class=\"data row3 col2\" >19.68%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b1fd_level0_row4\" class=\"row_heading level0 row4\" >GOOGL</th>\n",
       "      <td id=\"T_5b1fd_row4_col0\" class=\"data row4 col0\" >-75.15%</td>\n",
       "      <td id=\"T_5b1fd_row4_col1\" class=\"data row4 col1\" >14.29%</td>\n",
       "      <td id=\"T_5b1fd_row4_col2\" class=\"data row4 col2\" >1.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b1fd_level0_row5\" class=\"row_heading level0 row5\" >TSLA</th>\n",
       "      <td id=\"T_5b1fd_row5_col0\" class=\"data row5 col0\" >10.16%</td>\n",
       "      <td id=\"T_5b1fd_row5_col1\" class=\"data row5 col1\" >14.29%</td>\n",
       "      <td id=\"T_5b1fd_row5_col2\" class=\"data row5 col2\" >9.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b1fd_level0_row6\" class=\"row_heading level0 row6\" >XOM</th>\n",
       "      <td id=\"T_5b1fd_row6_col0\" class=\"data row6 col0\" >14.53%</td>\n",
       "      <td id=\"T_5b1fd_row6_col1\" class=\"data row6 col1\" >14.29%</td>\n",
       "      <td id=\"T_5b1fd_row6_col2\" class=\"data row6 col2\" >8.64%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2a8a480c6e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sample_w.style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfb5f5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Sharpe_Ratio</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Excess Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w_tan</th>\n",
       "      <td>0.471913</td>\n",
       "      <td>0.331179</td>\n",
       "      <td>1.424947</td>\n",
       "      <td>-0.120234</td>\n",
       "      <td>2.975133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_equally_weighted</th>\n",
       "      <td>0.293432</td>\n",
       "      <td>0.260804</td>\n",
       "      <td>1.125106</td>\n",
       "      <td>-0.296262</td>\n",
       "      <td>1.672516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_tan_reg</th>\n",
       "      <td>0.325593</td>\n",
       "      <td>0.260874</td>\n",
       "      <td>1.248085</td>\n",
       "      <td>-0.364960</td>\n",
       "      <td>1.859803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Mean  Volatility  Sharpe_Ratio      Skew  \\\n",
       "w_tan               0.471913    0.331179      1.424947 -0.120234   \n",
       "w_equally_weighted  0.293432    0.260804      1.125106 -0.296262   \n",
       "w_tan_reg           0.325593    0.260874      1.248085 -0.364960   \n",
       "\n",
       "                    Excess Kurtosis  \n",
       "w_tan                      2.975133  \n",
       "w_equally_weighted         1.672516  \n",
       "w_tan_reg                  1.859803  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sample_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9255bdd",
   "metadata": {},
   "source": [
    "## 5.\n",
    "\n",
    "Report the out-of-sample (2023) performance of all three portfolios in terms of annualized mean, vol, and Sharpe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6b408f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retsx_after_2022 = retsx[retsx.index > \"2022-12-31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c29a662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Sharpe_Ratio</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Excess Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w_tan</th>\n",
       "      <td>1.204709</td>\n",
       "      <td>0.443716</td>\n",
       "      <td>2.715043</td>\n",
       "      <td>-0.115814</td>\n",
       "      <td>-0.206600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_equally_weighted</th>\n",
       "      <td>0.955133</td>\n",
       "      <td>0.246953</td>\n",
       "      <td>3.867668</td>\n",
       "      <td>-0.171646</td>\n",
       "      <td>0.645163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_tan_reg</th>\n",
       "      <td>1.013509</td>\n",
       "      <td>0.250254</td>\n",
       "      <td>4.049917</td>\n",
       "      <td>-0.151873</td>\n",
       "      <td>0.125547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Mean  Volatility  Sharpe_Ratio      Skew  \\\n",
       "w_tan               1.204709    0.443716      2.715043 -0.115814   \n",
       "w_equally_weighted  0.955133    0.246953      3.867668 -0.171646   \n",
       "w_tan_reg           1.013509    0.250254      4.049917 -0.151873   \n",
       "\n",
       "                    Excess Kurtosis  \n",
       "w_tan                     -0.206600  \n",
       "w_equally_weighted         0.645163  \n",
       "w_tan_reg                  0.125547  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(retsx_after_2022 @ in_sample_w, adj_factor = 52)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65554c5",
   "metadata": {},
   "source": [
    "## 6.\n",
    "\n",
    "Imagine just for this problem that this data is for **total** returns, not excess returns.\n",
    "\n",
    "Report the weights of the global-minimum-variance portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "789915e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_MV(return_db, adj_factor = 12):\n",
    "    sigma = (return_db.cov()*adj_factor)\n",
    "    mu_excess = np.ones(len(return_db.columns))\n",
    "    vector = np.ones(len(return_db.columns))\n",
    "    w_tan = (np.linalg.inv(sigma) @ mu_excess )/(np.transpose(vector) @ np.linalg.inv(sigma) @ mu_excess)\n",
    "    weights_db = pd.DataFrame({\"w_MV\": w_tan})\n",
    "    weights_db.index = return_db.columns\n",
    "    return weights_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "385db248",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_MV = weights_MV(retsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d61a2db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_MV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.206231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>0.491250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>0.160866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>-0.119168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.011378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>-0.046927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>0.296369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           w_MV\n",
       "AAPL   0.206231\n",
       "MSFT   0.491250\n",
       "AMZN   0.160866\n",
       "NVDA  -0.119168\n",
       "GOOGL  0.011378\n",
       "TSLA  -0.046927\n",
       "XOM    0.296369"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_MV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "616c5114",
   "metadata": {},
   "outputs": [],
   "source": [
    "MV_metrics = get_metrics(retsx @ w_MV, adj_factor = 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "099c5a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Sharpe_Ratio</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Excess Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w_MV</th>\n",
       "      <td>0.180652</td>\n",
       "      <td>0.202905</td>\n",
       "      <td>0.890329</td>\n",
       "      <td>-0.443317</td>\n",
       "      <td>2.620049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean  Volatility  Sharpe_Ratio      Skew  Excess Kurtosis\n",
       "w_MV  0.180652    0.202905      0.890329 -0.443317         2.620049"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MV_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61946fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_metrics = get_metrics(retsx @ w_tanget, adj_factor = 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fccb14fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Sharpe_Ratio</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Excess Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w_tan</th>\n",
       "      <td>0.524255</td>\n",
       "      <td>0.340746</td>\n",
       "      <td>1.538553</td>\n",
       "      <td>-0.077035</td>\n",
       "      <td>2.531587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean  Volatility  Sharpe_Ratio      Skew  Excess Kurtosis\n",
       "w_tan  0.524255    0.340746      1.538553 -0.077035         2.531587"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b41a996",
   "metadata": {},
   "source": [
    "## 7.\n",
    "\n",
    "To target a mean return of 0.005%, would you be long or short this global minimum variance portfolio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cdf1aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_target = 0.005/100\n",
    "postion_tanget = (r_target-0.180652\t)/(0.524255-0.180652)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bcc2fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MV portfolio in order to achive a target return of 0.005% is 152.56%, then it's a long position \n"
     ]
    }
   ],
   "source": [
    "print(f\"The MV portfolio in order to achive a target return of 0.005% is {(1 - postion_tanget)*100:.2f}%, then it's a long position \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cdbfa9",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34d9fbd",
   "metadata": {},
   "source": [
    "# 3. Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426af123",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "Report the following performance metrics of excess returns for Tesla (`TSLA`).\n",
    "* skewness\n",
    "* kurtosis\n",
    "\n",
    "You are not annualizing any of these stats.\n",
    "\n",
    "What do these metrics indicate about the nature of the returns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0e16c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mean               0.131476\n",
       "Volatility         0.291606\n",
       "Sharpe_Ratio       0.450868\n",
       "Skew               0.439764\n",
       "Excess Kurtosis    1.492697\n",
       "Name: TSLA, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(retsx).loc[\"TSLA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0acfb2e",
   "metadata": {},
   "source": [
    "We can interpreted that the returns of TSLA does not have a normal distribution, due to Skewness > 0 -> Big positive returns and Kurtosis < 3 -> Fat Tails "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877253fc",
   "metadata": {},
   "source": [
    "## 2. \n",
    "\n",
    "Report the maximum drawdown for `TSLA` over the sample.\n",
    "* Ignore that your data is in excess returns rather than total returns.\n",
    "* Simply proceed with the excess return data for this calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff9bd008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6821852296331565"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics_all(retsx,adj_factor = 52).loc[\"TSLA\",\"Max Drawdown\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d77a74",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "For `TSLA`, calculate the following metrics, relative to `SPY`:\n",
    "* market beta\n",
    "* alpha\n",
    "* sortino ratio\n",
    "\n",
    "Annualize alpha and sortino ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba610fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def benchmark_regresion(data,benchmark = \"SPY US Equity\",adj = 12):\n",
    "    result = pd.DataFrame()\n",
    "    for asset in data.drop([benchmark],axis=1).columns:\n",
    "        X = sm.add_constant(data[benchmark])\n",
    "        y = data[asset]\n",
    "        mod = sm.OLS(y, X).fit()\n",
    "        inter, beta = mod.params.values[0], mod.params.values[1]\n",
    "        rsquare = mod.rsquared\n",
    "        std_errors= mod.resid.std()\n",
    "        TR = (y.mean()/beta)*adj\n",
    "        IR = (inter/std_errors)*np.sqrt(adj)\n",
    "        Sortino = y.mean()/data[data[asset]<0][asset].std() * np.sqrt(adj)\n",
    "        aux_result = pd.DataFrame([[inter*adj,beta,rsquare,std_errors,y.mean()*adj,TR,IR,Sortino]],columns=[\"Alpha\",\"Beta\",\"R-square\",\"std_errors\",\"R_mean\",\"Treynor Ratio\",\"Information Ratio\",\"Sortino Ratio\"], index = [asset])\n",
    "        result = pd.concat([result,aux_result],axis=0)\n",
    "    return result\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2820b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = pd.merge(retsx,spy,left_index=True,right_index=True,how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "520ef075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alpha            0.309470\n",
       "Beta             1.776825\n",
       "Sortino Ratio    1.642329\n",
       "Name: TSLA, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_regresion(returns,benchmark = \"SPY\",adj = 52).loc[\"TSLA\",[\"Alpha\",\"Beta\",\"Sortino Ratio\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7919b2",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "Continuing with `TSLA`, calculate the full-sample, 5th-percentile CVaR.\n",
    "* Use the `normal` formula, assuming mean returns are zero.\n",
    "* Use the full-sample volatility.\n",
    "\n",
    "Use the entire sample to calculate a single CVaR number. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0ab564",
   "metadata": {},
   "source": [
    "CVaR Parametric (q = `0.05`):\n",
    "\n",
    "$$ \\sigma * (-norm.pdf(1.65)/0.05)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0e5eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CVaR_parametric(data, alpha = 0.05):\n",
    "    return data.std()*(-norm.pdf(1.65)/alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d37d0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSLA   -0.172172\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CVaR_parametric(retsx[[\"TSLA\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94065e1d",
   "metadata": {},
   "source": [
    "## 5.\n",
    "\n",
    "Now calculate the 5th-percentile, one-period ahead, **VaR** for `TSLA`.\n",
    "\n",
    "Here, calculate the running series of VaR estimates.\n",
    "\n",
    "Again, \n",
    "* use the normal formula, with mean zero.\n",
    "\n",
    "But now, use the rolling volatility, based on \n",
    "* rolling window or $m=52$ weeks.\n",
    "\n",
    "Report the final 5 values of your calculated VaR series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rolling_window_VaR_CVaR(data, asset, alpha = 0.05, m = 52):\n",
    "    data = data[[asset]]\n",
    "    data[\"Rolling_Vol\"] = np.sqrt((data.shift()[asset]**2).rolling(m).mean())\n",
    "    data[\"Rolling_VaR\"] = data[\"Rolling_Vol\"]*(-1.65)#round(norm.ppf(alpha),2)\n",
    "    data[\"Rolling_CVaR\"] = data[\"Rolling_Vol\"]*(-norm.pdf(round(norm.ppf(alpha)))/alpha)\n",
    "    Hit_Ratio = data.loc[data[asset] < data[\"Rolling_VaR\"],asset].count()/len(data[\"Rolling_VaR\"].dropna())\n",
    "    return data, Hit_Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a46b3266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2023-06-16   -0.157886\n",
       "2023-06-23   -0.157712\n",
       "2023-06-30   -0.155459\n",
       "2023-07-07   -0.153663\n",
       "2023-07-14   -0.152046\n",
       "Name: TSLA, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = -1.65 * retsx[\"TSLA\"].rolling(52).std().shift().dropna()\n",
    "var.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d4d62ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josel\\AppData\\Local\\Temp\\ipykernel_47220\\3860848222.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"Rolling_Vol\"] = np.sqrt((data.shift()[asset]**2).rolling(m).mean())\n",
      "C:\\Users\\josel\\AppData\\Local\\Temp\\ipykernel_47220\\3860848222.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"Rolling_VaR\"] = data[\"Rolling_Vol\"]*(-1.65)#round(norm.ppf(alpha),2)\n",
      "C:\\Users\\josel\\AppData\\Local\\Temp\\ipykernel_47220\\3860848222.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"Rolling_CVaR\"] = data[\"Rolling_Vol\"]*(-norm.pdf(round(norm.ppf(alpha)))/alpha)\n"
     ]
    }
   ],
   "source": [
    "data, Hit_Ratio = Rolling_window_VaR_CVaR(retsx, \"TSLA\", alpha = 0.05, m = 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f5fa29fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2023-06-16   -0.156624\n",
       "2023-06-23   -0.156740\n",
       "2023-06-30   -0.154200\n",
       "2023-07-07   -0.152694\n",
       "2023-07-14   -0.150967\n",
       "Name: Rolling_VaR, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Rolling_VaR\"].tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a30cac",
   "metadata": {},
   "source": [
    "## 6. \n",
    "\n",
    "Calculate the out-of-sample **hit ratio** for your VaR series reported in your previous answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b7788afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05588235294117647"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hit_Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efee2bb2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3820d1b",
   "metadata": {},
   "source": [
    "# 4. Hedging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b559f9a9",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "Consider the following scenario: you are holding a \\$100 million long position in `NVDA`. You wish to hedge the position using some combination of \n",
    "* `AAPL`\n",
    "* `AMZN`\n",
    "* `GOOGL`\n",
    "* `MSFT`\n",
    "\n",
    "Report the positions you would hold of those 4 securities for an optimal hedge.\n",
    "\n",
    "Note:\n",
    "* In the regression estimation, include an intercept.\n",
    "* Use the full-sample regression. No need to worry about in-sample versus out-of-sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "153421f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear_Factor_Descomposition(data, y_asset,x_asset, adj = 12, constant = True):\n",
    "\n",
    "    Y = data[y_asset]\n",
    "    X = data[x_asset]\n",
    "\n",
    "    if constant:\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "    mod = sm.OLS(Y, X).fit()\n",
    "    inter = mod.params.values[0]\n",
    "\n",
    "    rsquare = mod.rsquared\n",
    "    std_errors= mod.resid.std()\n",
    "    tracking_error = mod.resid.std() * np.sqrt(adj)\n",
    "\n",
    "    metrics = pd.DataFrame([[inter,inter*adj,rsquare,std_errors,tracking_error]],columns=[\"Alpha\",\"Alpha Adj\",\"R-square\",\"std_errors\",\"tracking_error\"], index = [y_asset])\n",
    "    return pd.DataFrame(mod.params).T, metrics,mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7bfe8362",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta, metrics,summary = Linear_Factor_Descomposition(retsx, y_asset = \"NVDA\",x_asset = [\"AAPL\",\"AMZN\",\"GOOGL\",\"MSFT\"], adj = 52,constant = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c9eac323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_78d20\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_78d20_level0_col0\" class=\"col_heading level0 col0\" >AAPL</th>\n",
       "      <th id=\"T_78d20_level0_col1\" class=\"col_heading level0 col1\" >AMZN</th>\n",
       "      <th id=\"T_78d20_level0_col2\" class=\"col_heading level0 col2\" >GOOGL</th>\n",
       "      <th id=\"T_78d20_level0_col3\" class=\"col_heading level0 col3\" >MSFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_78d20_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_78d20_row0_col0\" class=\"data row0 col0\" >$-34,168,649</td>\n",
       "      <td id=\"T_78d20_row0_col1\" class=\"data row0 col1\" >$-41,725,986</td>\n",
       "      <td id=\"T_78d20_row0_col2\" class=\"data row0 col2\" >$784,795</td>\n",
       "      <td id=\"T_78d20_row0_col3\" class=\"data row0 col3\" >$-58,789,673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2a8a7c93bf0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount invested: $-133,899,513\n"
     ]
    }
   ],
   "source": [
    "display((beta[[\"AAPL\",\"AMZN\",\"GOOGL\",\"MSFT\"]] * -100_000_000).style.format('${:,.0f}'))\n",
    "print(f\"Total amount invested: ${(beta[[\"AAPL\",\"AMZN\",\"GOOGL\",\"MSFT\"]] * -100_000_000).sum(axis=1)[0]:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6127f366",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "How well does the hedge do? Cite a regression statistic to support your answer.\n",
    "\n",
    "Also estimate the volatility of the basis, (epsilon.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2a7e82a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>NVDA</td>       <th>  R-squared:         </th> <td>   0.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   81.81</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 19 Oct 2024</td> <th>  Prob (F-statistic):</th> <td>2.85e-50</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:03:16</td>     <th>  Log-Likelihood:    </th> <td>  636.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>  -1263.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   387</td>      <th>  BIC:               </th> <td>  -1243.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0053</td> <td>    0.002</td> <td>    2.134</td> <td> 0.033</td> <td>    0.000</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AAPL</th>  <td>    0.3417</td> <td>    0.084</td> <td>    4.045</td> <td> 0.000</td> <td>    0.176</td> <td>    0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AMZN</th>  <td>    0.4173</td> <td>    0.079</td> <td>    5.269</td> <td> 0.000</td> <td>    0.262</td> <td>    0.573</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GOOGL</th> <td>   -0.0078</td> <td>    0.102</td> <td>   -0.077</td> <td> 0.939</td> <td>   -0.208</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MSFT</th>  <td>    0.5879</td> <td>    0.126</td> <td>    4.669</td> <td> 0.000</td> <td>    0.340</td> <td>    0.835</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>117.513</td> <th>  Durbin-Watson:     </th> <td>   1.766</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 529.636</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.224</td>  <th>  Prob(JB):          </th> <td>9.79e-116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.141</td>  <th>  Cond. No.          </th> <td>    58.4</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       NVDA       & \\textbf{  R-squared:         } &     0.458   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.453   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     81.81   \\\\\n",
       "\\textbf{Date:}             & Sat, 19 Oct 2024 & \\textbf{  Prob (F-statistic):} &  2.85e-50   \\\\\n",
       "\\textbf{Time:}             &     20:03:16     & \\textbf{  Log-Likelihood:    } &    636.39   \\\\\n",
       "\\textbf{No. Observations:} &         392      & \\textbf{  AIC:               } &    -1263.   \\\\\n",
       "\\textbf{Df Residuals:}     &         387      & \\textbf{  BIC:               } &    -1243.   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       0.0053  &        0.002     &     2.134  &         0.033        &        0.000    &        0.010     \\\\\n",
       "\\textbf{AAPL}  &       0.3417  &        0.084     &     4.045  &         0.000        &        0.176    &        0.508     \\\\\n",
       "\\textbf{AMZN}  &       0.4173  &        0.079     &     5.269  &         0.000        &        0.262    &        0.573     \\\\\n",
       "\\textbf{GOOGL} &      -0.0078  &        0.102     &    -0.077  &         0.939        &       -0.208    &        0.192     \\\\\n",
       "\\textbf{MSFT}  &       0.5879  &        0.126     &     4.669  &         0.000        &        0.340    &        0.835     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 117.513 & \\textbf{  Durbin-Watson:     } &     1.766  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &   529.636  \\\\\n",
       "\\textbf{Skew:}          &   1.224 & \\textbf{  Prob(JB):          } & 9.79e-116  \\\\\n",
       "\\textbf{Kurtosis:}      &   8.141 & \\textbf{  Cond. No.          } &      58.4  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   NVDA   R-squared:                       0.458\n",
       "Model:                            OLS   Adj. R-squared:                  0.453\n",
       "Method:                 Least Squares   F-statistic:                     81.81\n",
       "Date:                Sat, 19 Oct 2024   Prob (F-statistic):           2.85e-50\n",
       "Time:                        20:03:16   Log-Likelihood:                 636.39\n",
       "No. Observations:                 392   AIC:                            -1263.\n",
       "Df Residuals:                     387   BIC:                            -1243.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0053      0.002      2.134      0.033       0.000       0.010\n",
       "AAPL           0.3417      0.084      4.045      0.000       0.176       0.508\n",
       "AMZN           0.4173      0.079      5.269      0.000       0.262       0.573\n",
       "GOOGL         -0.0078      0.102     -0.077      0.939      -0.208       0.192\n",
       "MSFT           0.5879      0.126      4.669      0.000       0.340       0.835\n",
       "==============================================================================\n",
       "Omnibus:                      117.513   Durbin-Watson:                   1.766\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              529.636\n",
       "Skew:                           1.224   Prob(JB):                    9.79e-116\n",
       "Kurtosis:                       8.141   Cond. No.                         58.4\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "baa052c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Alpha Adj</th>\n",
       "      <th>R-square</th>\n",
       "      <th>std_errors</th>\n",
       "      <th>tracking_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>0.005264</td>\n",
       "      <td>0.273752</td>\n",
       "      <td>0.458168</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>0.344562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Alpha  Alpha Adj  R-square  std_errors  tracking_error\n",
       "NVDA  0.005264   0.273752  0.458168    0.047782        0.344562"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb177a5f",
   "metadata": {},
   "source": [
    "The R-Square value is relatively low at 45.81%, indicating that NDVA could potentially be hedged with a different combination of assets and the current hedge only cover 46% of the variance of NVDA. Upon examining the statistical summary, it is evident that both the intercept and the beta coefficient for GOOGL are low, suggesting that GOOGL is not a significant predictor in the model. Consequently, we can re-estimate the regression by excluding the intercept and GOOGL. This adjustment results in an increased R-Square value of 47%, and all remaining variables become statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "57737f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      AAPL      AMZN      MSFT\n",
       " 0  0.35139  0.413544  0.602423,\n",
       "         Alpha  R-square  std_errors\n",
       " NVDA  0.35139  0.471434    0.047791,\n",
       " <class 'statsmodels.iolib.summary.Summary'>\n",
       " \"\"\"\n",
       "                                  OLS Regression Results                                \n",
       " =======================================================================================\n",
       " Dep. Variable:                   NVDA   R-squared (uncentered):                   0.471\n",
       " Model:                            OLS   Adj. R-squared (uncentered):              0.467\n",
       " Method:                 Least Squares   F-statistic:                              115.7\n",
       " Date:                Sat, 19 Oct 2024   Prob (F-statistic):                    1.51e-53\n",
       " Time:                        19:54:00   Log-Likelihood:                          634.08\n",
       " No. Observations:                 392   AIC:                                     -1262.\n",
       " Df Residuals:                     389   BIC:                                     -1250.\n",
       " Df Model:                           3                                                  \n",
       " Covariance Type:            nonrobust                                                  \n",
       " ==============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       " ------------------------------------------------------------------------------\n",
       " AAPL           0.3514      0.083      4.230      0.000       0.188       0.515\n",
       " AMZN           0.4135      0.076      5.407      0.000       0.263       0.564\n",
       " MSFT           0.6024      0.113      5.332      0.000       0.380       0.825\n",
       " ==============================================================================\n",
       " Omnibus:                      116.916   Durbin-Watson:                   1.748\n",
       " Prob(Omnibus):                  0.000   Jarque-Bera (JB):              521.068\n",
       " Skew:                           1.221   Prob(JB):                    7.10e-114\n",
       " Kurtosis:                       8.093   Cond. No.                         3.09\n",
       " ==============================================================================\n",
       " \n",
       " Notes:\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       " \"\"\")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Linear_Factor_Descomposition(retsx, y_asset = \"NVDA\",x_asset = [\"AAPL\",\"AMZN\",\"MSFT\"], constant = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579b6394",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "Report the annualized intercept. By including this intercept, what are you assuming about the nature of the returns of `NVDA` as well as the returns of the hedging instruments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5cf1d9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Alpha Adj</th>\n",
       "      <th>R-square</th>\n",
       "      <th>std_errors</th>\n",
       "      <th>tracking_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>0.005264</td>\n",
       "      <td>0.273752</td>\n",
       "      <td>0.458168</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>0.344562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Alpha  Alpha Adj  R-square  std_errors  tracking_error\n",
       "NVDA  0.005264   0.273752  0.458168    0.047782        0.344562"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3944e49b",
   "metadata": {},
   "source": [
    "By including the intercept, we are assuming that the sample averages are not good predictors of the future averages. Thus we are allowing an intercept in the hedging regression, to ensure differences in mean returns do not impact the betas, which are the hedge recommendations.\n",
    "\n",
    "If we really believed these sample averages are predictive, we would want the hedge ratios to account for that, and thus exclude an intercept, forcing these averages to impact the betas."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
